{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-05T05:27:30.224065Z",
     "iopub.status.busy": "2022-02-05T05:27:30.223815Z",
     "iopub.status.idle": "2022-02-05T05:28:00.773217Z",
     "shell.execute_reply": "2022-02-05T05:28:00.772245Z",
     "shell.execute_reply.started": "2022-02-05T05:27:30.224037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision in c:\\users\\dell\\appdata\\roaming\\python\\python36\\site-packages (0.11.3)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\dell\\appdata\\roaming\\python\\python36\\site-packages (from torchvision) (8.3.1)\n",
      "Requirement already satisfied: torch==1.10.2 in c:\\users\\dell\\appdata\\roaming\\python\\python36\\site-packages (from torchvision) (1.10.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\appdata\\roaming\\python\\python36\\site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dell\\appdata\\roaming\\python\\python36\\site-packages (from torch==1.10.2->torchvision) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\dell\\appdata\\roaming\\python\\python36\\site-packages (from torch==1.10.2->torchvision) (0.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    }
   ],
   "source": [
    "# !pip install tqdm\n",
    "# !pip install openpyxl\n",
    "# !pip install deep_translator\n",
    "# !pip install NLPAug\n",
    "# !pip install gensim\n",
    "!pip install torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T05:28:00.77557Z",
     "iopub.status.busy": "2022-02-05T05:28:00.775287Z",
     "iopub.status.idle": "2022-02-05T05:28:08.47217Z",
     "shell.execute_reply": "2022-02-05T05:28:08.471277Z",
     "shell.execute_reply.started": "2022-02-05T05:28:00.775535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer #word lemma class\n",
    "from deep_translator import GoogleTranslator # import google translator.\n",
    "from tqdm import tqdm \n",
    "tqdm.pandas()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.layers import Conv1D,Input, Bidirectional, LSTM, Dense, SpatialDropout1D, Input, Dropout,Embedding,Concatenate, TimeDistributed , BatchNormalization,Flatten,Activation\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pickle\n",
    "lemma = WordNetLemmatizer()\n",
    "Gtrans= GoogleTranslator(source='auto', target='english')\n",
    "#initialize and download words,stopword and wordnet word corpus.\n",
    "words = set(nltk.corpus.words.words())\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T05:28:08.473749Z",
     "iopub.status.busy": "2022-02-05T05:28:08.473489Z",
     "iopub.status.idle": "2022-02-05T05:28:09.45987Z",
     "shell.execute_reply": "2022-02-05T05:28:09.459374Z",
     "shell.execute_reply.started": "2022-02-05T05:28:08.473724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Short description                                        Description  \\\n",
      "0       login issue  -verified user details.(employee# & manager na...   \n",
      "1           outlook  \\r\\n\\r\\nreceived from: hmjdrvpb.komuaywn@gmail...   \n",
      "\n",
      "              Caller Assignment group  \n",
      "0  spxjnwir pjlcoqds            GRP_0  \n",
      "1  hmjdrvpb komuaywn            GRP_0  \n"
     ]
    }
   ],
   "source": [
    "ticket=pd.read_excel('input_data automated ticket dataset.xlsx')\n",
    "print(ticket.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T05:28:09.461571Z",
     "iopub.status.busy": "2022-02-05T05:28:09.461303Z",
     "iopub.status.idle": "2022-02-05T05:28:09.474257Z",
     "shell.execute_reply": "2022-02-05T05:28:09.473622Z",
     "shell.execute_reply.started": "2022-02-05T05:28:09.461547Z"
    }
   },
   "outputs": [],
   "source": [
    "ticket['Description'].fillna(ticket['Short description'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T05:28:09.476413Z",
     "iopub.status.busy": "2022-02-05T05:28:09.475485Z",
     "iopub.status.idle": "2022-02-05T05:28:09.490426Z",
     "shell.execute_reply": "2022-02-05T05:28:09.489908Z",
     "shell.execute_reply.started": "2022-02-05T05:28:09.476377Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define function for cleaning.\n",
    "def dataCleaner(text):\n",
    "    \n",
    "    #remove x000d from text.\n",
    "    text=text.replace('_x000D_',' ')\n",
    "    \n",
    "    #remove ? from text.\n",
    "    text=text.replace('?',' ')\n",
    "    \n",
    "    #correct acct to account.\n",
    "    text=text.replace('acct','account')\n",
    "    \n",
    "    #correct fw to forward.\n",
    "    text=text.replace('fw:','forward')\n",
    "    \n",
    "    #correct fw to forward.\n",
    "    text=text.replace(' fw ',' forward ')\n",
    "    \n",
    "    #remove (employee# & manager name)    \n",
    "    #text=text.replace('(employee# & manager name)',' ')\n",
    "        \n",
    "    #remove subject:    \n",
    "    #text=text.replace('subject:',' ')    \n",
    "    \n",
    "    #Remove received from: email\n",
    "   \n",
    "    \n",
    "    #Remove hex chars\n",
    "    lst = re.findall('==pcap 1 hex s==[\\w\\W]*==pcap 1 hex e==', text)\n",
    "    for i in lst:\n",
    "        text=text.replace(i,' ')\n",
    "        \n",
    "    #Remove ascii chars\n",
    "    lst = re.findall('==pcap 1 ascii s==[\\w\\W]*==pcap 1 ascii e==', text)\n",
    "    for i in lst:\n",
    "        text=text.replace(i,' ')\n",
    "        \n",
    "    #Remove correlation data \n",
    "    lst = re.findall('\\[correlation_data\\](.*\\n){2}', text)\n",
    "    for i in lst:\n",
    "        text=text.replace(i,' ')\n",
    "       \n",
    "    #Remove [correlation_data]\n",
    "    lst = re.findall('\\[correlation_data\\]', text)\n",
    "    for i in lst:\n",
    "        text=text.replace(i,' ')\n",
    "        \n",
    "    #Remove [no entry] \n",
    "    lst = re.findall('\\[no entry\\]', text)\n",
    "    for i in lst:\n",
    "        text=text.replace(i,' ')\n",
    "        \n",
    "    #Remove ascii packet(s):\n",
    "    text=text.replace('ascii packet(s):',' ')\n",
    "    \n",
    "    #Remove hex packet(s)::\n",
    "    text=text.replace('hex packet(s):',' ')\n",
    "        \n",
    "    # Removing white spaces and trimmign the space around words.\n",
    "    text = re.sub(' +', ' ', text.strip())\n",
    "    \n",
    "    #removee tabs\n",
    "    text=text.replace('\\t',' ')\n",
    "    \n",
    "    text=text.replace('\\r',' ')\n",
    "    \n",
    "    #Remove new lines.\n",
    "    text=text.replace('\\n',' ')\n",
    "    \n",
    "    # We will use google translate to translate the sentence to english.\n",
    "    if(len(text)>4000):\n",
    "        n=3000\n",
    "        GtransStrings = []\n",
    "        for index in range(0, len(text), n):\n",
    "            separated_strings = text[index : index + n]\n",
    "            GtransStrings.append(Gtrans.translate(separated_strings))\n",
    "        text=\" \".join(GtransStrings)\n",
    "        \n",
    "    else:\n",
    "        if(text!=''):\n",
    "            text=Gtrans.translate(text)\n",
    "            \n",
    "    # Changing to lower case all the words.\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    \n",
    "    # Removing english stop words.\n",
    "    text = [word.strip() for word in text if not word in set(stopwords.words('english'))]\n",
    "    \n",
    "    # lemmatizing the words to their base forms\n",
    "    text = [lemma.lemmatize(word) for word in text]\n",
    "    \n",
    "    # Joining back the text.\n",
    "    text = ' '.join(text)\n",
    "   \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T05:28:09.491777Z",
     "iopub.status.busy": "2022-02-05T05:28:09.491332Z",
     "iopub.status.idle": "2022-02-05T05:48:13.06109Z",
     "shell.execute_reply": "2022-02-05T05:48:13.059981Z",
     "shell.execute_reply.started": "2022-02-05T05:28:09.491744Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now lets clean all the text columns in the dataframe.\n",
    "# ticket['CleanedDescription'] = ticket['Description'].progress_apply(dataCleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T05:48:13.062261Z",
     "iopub.status.busy": "2022-02-05T05:48:13.062089Z",
     "iopub.status.idle": "2022-02-05T05:48:13.13514Z",
     "shell.execute_reply": "2022-02-05T05:48:13.134578Z",
     "shell.execute_reply.started": "2022-02-05T05:48:13.062238Z"
    }
   },
   "outputs": [],
   "source": [
    "# ticket.to_csv('./semicleaned2.csv',index=False)\n",
    "ticket = pd.read_csv('./semicleaned2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T05:48:13.136746Z",
     "iopub.status.busy": "2022-02-05T05:48:13.136385Z",
     "iopub.status.idle": "2022-02-05T05:48:13.14909Z",
     "shell.execute_reply": "2022-02-05T05:48:13.148065Z",
     "shell.execute_reply.started": "2022-02-05T05:48:13.136718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Short description      8\n",
       "Description            0\n",
       "Caller                 0\n",
       "Assignment group       0\n",
       "CleanedDescription    59\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticket.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T05:48:13.150566Z",
     "iopub.status.busy": "2022-02-05T05:48:13.150345Z",
     "iopub.status.idle": "2022-02-05T05:48:13.166047Z",
     "shell.execute_reply": "2022-02-05T05:48:13.165504Z",
     "shell.execute_reply.started": "2022-02-05T05:48:13.150535Z"
    }
   },
   "outputs": [],
   "source": [
    "ticket.drop(['Caller','Description','Short description'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T05:48:13.168869Z",
     "iopub.status.busy": "2022-02-05T05:48:13.168204Z",
     "iopub.status.idle": "2022-02-05T05:48:13.176502Z",
     "shell.execute_reply": "2022-02-05T05:48:13.176033Z",
     "shell.execute_reply.started": "2022-02-05T05:48:13.168836Z"
    }
   },
   "outputs": [],
   "source": [
    "ticket.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T05:48:13.17811Z",
     "iopub.status.busy": "2022-02-05T05:48:13.177465Z",
     "iopub.status.idle": "2022-02-05T05:48:13.189506Z",
     "shell.execute_reply": "2022-02-05T05:48:13.188457Z",
     "shell.execute_reply.started": "2022-02-05T05:48:13.178077Z"
    }
   },
   "outputs": [],
   "source": [
    "ticket['Group_Mod'] = ticket['Assignment group'].apply(lambda x: 'GRP_X' if x != 'GRP_0' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T05:48:13.191014Z",
     "iopub.status.busy": "2022-02-05T05:48:13.1906Z",
     "iopub.status.idle": "2022-02-05T05:48:13.213782Z",
     "shell.execute_reply": "2022-02-05T05:48:13.212763Z",
     "shell.execute_reply.started": "2022-02-05T05:48:13.190985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assignment group</th>\n",
       "      <th>CleanedDescription</th>\n",
       "      <th>Group_Mod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GRP_1</td>\n",
       "      <td>event: critical:hostname_221.company.com value...</td>\n",
       "      <td>GRP_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GRP_3</td>\n",
       "      <td>undocking pc , screen come back</td>\n",
       "      <td>GRP_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GRP_4</td>\n",
       "      <td>received from: kxsceyzo.naokumlb@gmail.com gen...</td>\n",
       "      <td>GRP_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>GRP_5</td>\n",
       "      <td>received from: yisohglr.uvteflgb@gmail.com hi ...</td>\n",
       "      <td>GRP_X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>GRP_6</td>\n",
       "      <td>received from: monitoring_tool@company.com job...</td>\n",
       "      <td>GRP_X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Assignment group                                 CleanedDescription  \\\n",
       "6             GRP_1  event: critical:hostname_221.company.com value...   \n",
       "17            GRP_3                    undocking pc , screen come back   \n",
       "32            GRP_4  received from: kxsceyzo.naokumlb@gmail.com gen...   \n",
       "43            GRP_5  received from: yisohglr.uvteflgb@gmail.com hi ...   \n",
       "47            GRP_6  received from: monitoring_tool@company.com job...   \n",
       "\n",
       "   Group_Mod  \n",
       "6      GRP_X  \n",
       "17     GRP_X  \n",
       "32     GRP_X  \n",
       "43     GRP_X  \n",
       "47     GRP_X  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp=ticket[ticket['Group_Mod']!='GRP_0'].copy()\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T05:48:13.215333Z",
     "iopub.status.busy": "2022-02-05T05:48:13.214958Z",
     "iopub.status.idle": "2022-02-05T05:48:13.219985Z",
     "shell.execute_reply": "2022-02-05T05:48:13.219272Z",
     "shell.execute_reply.started": "2022-02-05T05:48:13.215299Z"
    }
   },
   "outputs": [],
   "source": [
    "temp1=temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T05:48:13.221592Z",
     "iopub.status.busy": "2022-02-05T05:48:13.221046Z",
     "iopub.status.idle": "2022-02-05T05:48:27.980324Z",
     "shell.execute_reply": "2022-02-05T05:48:27.979449Z",
     "shell.execute_reply.started": "2022-02-05T05:48:13.221563Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4468/4468 [00:12<00:00, 364.61it/s]\n"
     ]
    }
   ],
   "source": [
    "aug = naw.SynonymAug(aug_src='wordnet', model_path=None, name='Synonym_Aug', aug_min=1, aug_max=10, aug_p=0.3,  \n",
    "                     stopwords=None, tokenizer=None, reverse_tokenizer=None, stopwords_regex=None, force_reload=False, \n",
    "                     verbose=0)\n",
    "temp1['CleanedDescription'] = temp1['CleanedDescription'].progress_apply(aug.augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:04:22.746277Z",
     "iopub.status.busy": "2022-02-05T06:04:22.745772Z",
     "iopub.status.idle": "2022-02-05T06:04:22.754027Z",
     "shell.execute_reply": "2022-02-05T06:04:22.753426Z",
     "shell.execute_reply.started": "2022-02-05T06:04:22.746235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4468\n",
      "4468\n"
     ]
    }
   ],
   "source": [
    "print(len(temp))\n",
    "print(len(temp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:04:22.75946Z",
     "iopub.status.busy": "2022-02-05T06:04:22.757578Z",
     "iopub.status.idle": "2022-02-05T06:04:22.77005Z",
     "shell.execute_reply": "2022-02-05T06:04:22.769424Z",
     "shell.execute_reply.started": "2022-02-05T06:04:22.759423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8936\n"
     ]
    }
   ],
   "source": [
    "newTemp1=pd.concat([temp,temp1])\n",
    "print(len(newTemp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:04:22.775548Z",
     "iopub.status.busy": "2022-02-05T06:04:22.773629Z",
     "iopub.status.idle": "2022-02-05T06:04:22.782133Z",
     "shell.execute_reply": "2022-02-05T06:04:22.781547Z",
     "shell.execute_reply.started": "2022-02-05T06:04:22.775512Z"
    }
   },
   "outputs": [],
   "source": [
    "XSmall=newTemp1['CleanedDescription']\n",
    "ySmall=newTemp1['Assignment group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:04:22.787549Z",
     "iopub.status.busy": "2022-02-05T06:04:22.785663Z",
     "iopub.status.idle": "2022-02-05T06:04:22.794114Z",
     "shell.execute_reply": "2022-02-05T06:04:22.793513Z",
     "shell.execute_reply.started": "2022-02-05T06:04:22.787514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8936,)\n",
      "(8936,)\n"
     ]
    }
   ],
   "source": [
    "print(XSmall.shape)\n",
    "print(ySmall.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:04:22.79571Z",
     "iopub.status.busy": "2022-02-05T06:04:22.7953Z",
     "iopub.status.idle": "2022-02-05T06:04:22.804171Z",
     "shell.execute_reply": "2022-02-05T06:04:22.803528Z",
     "shell.execute_reply.started": "2022-02-05T06:04:22.795657Z"
    }
   },
   "outputs": [],
   "source": [
    "XFull=ticket['CleanedDescription']\n",
    "yFull=ticket['Group_Mod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:04:22.805734Z",
     "iopub.status.busy": "2022-02-05T06:04:22.805332Z",
     "iopub.status.idle": "2022-02-05T06:04:22.813561Z",
     "shell.execute_reply": "2022-02-05T06:04:22.812994Z",
     "shell.execute_reply.started": "2022-02-05T06:04:22.805683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8441,)\n",
      "(8441,)\n"
     ]
    }
   ],
   "source": [
    "print(XFull.shape)\n",
    "print(yFull.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:04:22.815149Z",
     "iopub.status.busy": "2022-02-05T06:04:22.814737Z",
     "iopub.status.idle": "2022-02-05T06:04:23.119276Z",
     "shell.execute_reply": "2022-02-05T06:04:23.118005Z",
     "shell.execute_reply.started": "2022-02-05T06:04:22.815115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size : 18764\n",
      "Word Indices:  tool\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(lower=False)\n",
    "tokenizer.fit_on_texts(ticket['CleanedDescription'])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary Size :\", vocab_size)\n",
    "print(\"Word Indices: \", list(word_index.keys())[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:04:23.120714Z",
     "iopub.status.busy": "2022-02-05T06:04:23.120509Z",
     "iopub.status.idle": "2022-02-05T06:04:23.130474Z",
     "shell.execute_reply": "2022-02-05T06:04:23.129657Z",
     "shell.execute_reply.started": "2022-02-05T06:04:23.12067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FullEncoder=LabelEncoder()\n",
    "FullEncoder.fit(yFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:04:23.131856Z",
     "iopub.status.busy": "2022-02-05T06:04:23.131583Z",
     "iopub.status.idle": "2022-02-05T06:04:23.138595Z",
     "shell.execute_reply": "2022-02-05T06:04:23.137729Z",
     "shell.execute_reply.started": "2022-02-05T06:04:23.131823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "#max_len = max(ticket['detailLen'])\n",
    "max_len=200\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:04:23.140151Z",
     "iopub.status.busy": "2022-02-05T06:04:23.139926Z",
     "iopub.status.idle": "2022-02-05T06:04:23.362557Z",
     "shell.execute_reply": "2022-02-05T06:04:23.361978Z",
     "shell.execute_reply.started": "2022-02-05T06:04:23.140122Z"
    }
   },
   "outputs": [],
   "source": [
    "XFull = pad_sequences(tokenizer.texts_to_sequences(XFull), maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:04:23.363973Z",
     "iopub.status.busy": "2022-02-05T06:04:23.363766Z",
     "iopub.status.idle": "2022-02-05T06:04:23.368881Z",
     "shell.execute_reply": "2022-02-05T06:04:23.368212Z",
     "shell.execute_reply.started": "2022-02-05T06:04:23.363948Z"
    }
   },
   "outputs": [],
   "source": [
    "yFull=FullEncoder.transform(yFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:04:23.370203Z",
     "iopub.status.busy": "2022-02-05T06:04:23.370015Z",
     "iopub.status.idle": "2022-02-05T06:04:23.380493Z",
     "shell.execute_reply": "2022-02-05T06:04:23.379583Z",
     "shell.execute_reply.started": "2022-02-05T06:04:23.370179Z"
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:04:23.38466Z",
     "iopub.status.busy": "2022-02-05T06:04:23.384421Z",
     "iopub.status.idle": "2022-02-05T06:04:42.814638Z",
     "shell.execute_reply": "2022-02-05T06:04:42.813954Z",
     "shell.execute_reply.started": "2022-02-05T06:04:23.384635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Generate word embeddings\n",
    "# Construct the embedding weight matrix using the word embeddings via the tokenizer\n",
    "embeddings_index = dict()\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 15\n",
    "\n",
    "f = open('./glove.6B.300d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "print('Found %s word vectors.' %len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:04:42.815796Z",
     "iopub.status.busy": "2022-02-05T06:04:42.815598Z",
     "iopub.status.idle": "2022-02-05T06:04:42.830307Z",
     "shell.execute_reply": "2022-02-05T06:04:42.829431Z",
     "shell.execute_reply.started": "2022-02-05T06:04:42.815773Z"
    }
   },
   "outputs": [],
   "source": [
    "Xf_train, Xf_test, yf_train, yf_test =  train_test_split(XFull, yFull, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:04:42.83193Z",
     "iopub.status.busy": "2022-02-05T06:04:42.831637Z",
     "iopub.status.idle": "2022-02-05T06:04:42.838253Z",
     "shell.execute_reply": "2022-02-05T06:04:42.837415Z",
     "shell.execute_reply.started": "2022-02-05T06:04:42.831897Z"
    }
   },
   "outputs": [],
   "source": [
    "#defining callbacks\n",
    "callbacks = [    \n",
    "    ModelCheckpoint('./model-{val_loss:.2f}.h5', monitor=\"val_loss\", verbose=1, save_best_only=True, save_weights_only=False),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:04:42.840059Z",
     "iopub.status.busy": "2022-02-05T06:04:42.839812Z",
     "iopub.status.idle": "2022-02-05T06:04:43.92972Z",
     "shell.execute_reply": "2022-02-05T06:04:43.928685Z",
     "shell.execute_reply.started": "2022-02-05T06:04:42.84003Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, EMBEDDING_DIM, weights = [embedding_matrix], input_length = max_len, trainable = False))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True, input_shape=(None, 1))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#compile model\n",
    "LR = 0.01\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=Adam(learning_rate = LR),metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:04:43.931683Z",
     "iopub.status.busy": "2022-02-05T06:04:43.931359Z",
     "iopub.status.idle": "2022-02-05T06:24:30.86583Z",
     "shell.execute_reply": "2022-02-05T06:24:30.86531Z",
     "shell.execute_reply.started": "2022-02-05T06:04:43.931647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "185/185 [==============================] - 111s 580ms/step - loss: 0.4918 - accuracy: 0.7502 - val_loss: 0.4660 - val_accuracy: 0.8069\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.46598, saving model to .\\model-0.47.h5\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 109s 588ms/step - loss: 0.3885 - accuracy: 0.8240 - val_loss: 0.4037 - val_accuracy: 0.8141\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.46598 to 0.40365, saving model to .\\model-0.40.h5\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 111s 599ms/step - loss: 0.3821 - accuracy: 0.8257 - val_loss: 0.3871 - val_accuracy: 0.8125\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.40365 to 0.38708, saving model to .\\model-0.39.h5\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 113s 609ms/step - loss: 0.3210 - accuracy: 0.8600 - val_loss: 0.3784 - val_accuracy: 0.8322\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.38708 to 0.37840, saving model to .\\model-0.38.h5\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 116s 629ms/step - loss: 0.2852 - accuracy: 0.8802 - val_loss: 0.3881 - val_accuracy: 0.8267\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.37840\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 115s 619ms/step - loss: 0.2525 - accuracy: 0.8937 - val_loss: 0.3895 - val_accuracy: 0.8330\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.37840\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 115s 620ms/step - loss: 0.2182 - accuracy: 0.9154 - val_loss: 0.4442 - val_accuracy: 0.8239\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.37840\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 114s 619ms/step - loss: 0.1836 - accuracy: 0.9277 - val_loss: 0.4476 - val_accuracy: 0.8310\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.37840\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 115s 620ms/step - loss: 0.1812 - accuracy: 0.9311 - val_loss: 0.5032 - val_accuracy: 0.8310\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.37840\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2641a1387b8>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xf_train, yf_train, batch_size = 32, epochs = 10, validation_data = (Xf_test, yf_test), callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:24:30.867117Z",
     "iopub.status.busy": "2022-02-05T06:24:30.866852Z",
     "iopub.status.idle": "2022-02-05T06:24:30.873423Z",
     "shell.execute_reply": "2022-02-05T06:24:30.872729Z",
     "shell.execute_reply.started": "2022-02-05T06:24:30.867087Z"
    }
   },
   "outputs": [],
   "source": [
    "Xs_train, Xs_test, ys_train, ys_test =  train_test_split(XSmall, ySmall, test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:24:30.874826Z",
     "iopub.status.busy": "2022-02-05T06:24:30.874488Z",
     "iopub.status.idle": "2022-02-05T06:25:10.934278Z",
     "shell.execute_reply": "2022-02-05T06:25:10.933443Z",
     "shell.execute_reply.started": "2022-02-05T06:24:30.8748Z"
    }
   },
   "outputs": [],
   "source": [
    "#initialize the vectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=5 ,use_idf=True,analyzer='word', token_pattern=r'\\w{1,}')\n",
    "# We will fit on whole data set do that there shouldnt be any case where a word is present in train set and not in test.\n",
    "vectorizer.fit(XSmall)\n",
    "Xs_train = vectorizer.transform(Xs_train)\n",
    "Xs_test = vectorizer.transform(Xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:25:10.935735Z",
     "iopub.status.busy": "2022-02-05T06:25:10.93546Z",
     "iopub.status.idle": "2022-02-05T06:25:11.131212Z",
     "shell.execute_reply": "2022-02-05T06:25:11.130088Z",
     "shell.execute_reply.started": "2022-02-05T06:25:10.935684Z"
    }
   },
   "outputs": [],
   "source": [
    "Xs_train=Xs_train.toarray()\n",
    "Xs_test=Xs_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:25:11.132959Z",
     "iopub.status.busy": "2022-02-05T06:25:11.132724Z",
     "iopub.status.idle": "2022-02-05T06:25:11.140514Z",
     "shell.execute_reply": "2022-02-05T06:25:11.13979Z",
     "shell.execute_reply.started": "2022-02-05T06:25:11.132928Z"
    }
   },
   "outputs": [],
   "source": [
    "smallEncoder=LabelEncoder()\n",
    "smallEncoder.fit(ySmall)\n",
    "ys_train=smallEncoder.transform(ys_train)\n",
    "ys_test=smallEncoder.transform(ys_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:25:11.141992Z",
     "iopub.status.busy": "2022-02-05T06:25:11.141739Z",
     "iopub.status.idle": "2022-02-05T06:28:57.211363Z",
     "shell.execute_reply": "2022-02-05T06:28:57.20798Z",
     "shell.execute_reply.started": "2022-02-05T06:25:11.141959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "782/782 [==============================] - 7s 8ms/step - loss: -10957.2334 - accuracy: 0.0312\n",
      "Epoch 2/25\n",
      "782/782 [==============================] - 6s 8ms/step - loss: -77637.3281 - accuracy: 0.0312\n",
      "Epoch 3/25\n",
      "782/782 [==============================] - 6s 8ms/step - loss: -199490.7500 - accuracy: 0.0312\n",
      "Epoch 4/25\n",
      "782/782 [==============================] - 7s 8ms/step - loss: -365813.4062 - accuracy: 0.0312\n",
      "Epoch 5/25\n",
      "782/782 [==============================] - 7s 9ms/step - loss: -570401.5000 - accuracy: 0.0312\n",
      "Epoch 6/25\n",
      "782/782 [==============================] - 7s 9ms/step - loss: -809570.9375 - accuracy: 0.0312\n",
      "Epoch 7/25\n",
      "782/782 [==============================] - 7s 8ms/step - loss: -1081362.2500 - accuracy: 0.0312\n",
      "Epoch 8/25\n",
      "782/782 [==============================] - 7s 8ms/step - loss: -1386484.7500 - accuracy: 0.0312\n",
      "Epoch 9/25\n",
      "782/782 [==============================] - 6s 8ms/step - loss: -1723319.3750 - accuracy: 0.0312\n",
      "Epoch 10/25\n",
      "782/782 [==============================] - 7s 9ms/step - loss: -2091002.2500 - accuracy: 0.0312\n",
      "Epoch 11/25\n",
      "782/782 [==============================] - 7s 8ms/step - loss: -2489088.5000 - accuracy: 0.0312\n",
      "Epoch 12/25\n",
      "782/782 [==============================] - 6s 8ms/step - loss: -2916156.7500 - accuracy: 0.0312\n",
      "Epoch 13/25\n",
      "782/782 [==============================] - 6s 8ms/step - loss: -3372470.5000 - accuracy: 0.0312\n",
      "Epoch 14/25\n",
      "782/782 [==============================] - 6s 8ms/step - loss: -3860346.5000 - accuracy: 0.0312\n",
      "Epoch 15/25\n",
      "782/782 [==============================] - 7s 8ms/step - loss: -4377545.0000 - accuracy: 0.0312\n",
      "Epoch 16/25\n",
      "782/782 [==============================] - 7s 8ms/step - loss: -4924264.5000 - accuracy: 0.0312\n",
      "Epoch 17/25\n",
      "782/782 [==============================] - 6s 8ms/step - loss: -5500050.5000 - accuracy: 0.0312\n",
      "Epoch 18/25\n",
      "782/782 [==============================] - 7s 8ms/step - loss: -6102572.5000 - accuracy: 0.0312\n",
      "Epoch 19/25\n",
      "782/782 [==============================] - 7s 8ms/step - loss: -6733929.0000 - accuracy: 0.0312\n",
      "Epoch 20/25\n",
      "782/782 [==============================] - 6s 8ms/step - loss: -7395773.5000 - accuracy: 0.0312\n",
      "Epoch 21/25\n",
      "782/782 [==============================] - 7s 8ms/step - loss: -8088487.5000 - accuracy: 0.0312\n",
      "Epoch 22/25\n",
      "782/782 [==============================] - 7s 8ms/step - loss: -8810754.0000 - accuracy: 0.0312\n",
      "Epoch 23/25\n",
      "782/782 [==============================] - 7s 8ms/step - loss: -9562281.0000 - accuracy: 0.0312\n",
      "Epoch 24/25\n",
      "782/782 [==============================] - 7s 8ms/step - loss: -10344033.0000 - accuracy: 0.0312\n",
      "Epoch 25/25\n",
      "782/782 [==============================] - 7s 8ms/step - loss: -11155114.0000 - accuracy: 0.0312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26417e2fd68>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_outputs = 1\n",
    "n_inputs = Xs_train.shape[1]\n",
    "model = Sequential()\n",
    "# We will keep input shape as 200, the size of our feature list.\n",
    "model.add(Dense(512, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "# compile model with loss as binary_crossentropy and metrics as accuracy\n",
    "model.compile(loss='binary_crossentropy', metrics = ['accuracy'],optimizer='adam')\n",
    "\n",
    "#Train/fit the model\n",
    "model.fit(Xs_train, ys_train, batch_size=8, epochs=25,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T06:46:56.250105Z",
     "iopub.status.busy": "2022-02-05T06:46:56.249137Z",
     "iopub.status.idle": "2022-02-05T10:00:18.620529Z",
     "shell.execute_reply": "2022-02-05T10:00:18.616946Z",
     "shell.execute_reply.started": "2022-02-05T06:46:56.25005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 96 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=2.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_validation.py\", line 516, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\linear_model\\logistic.py\", line 1493, in fit\n    solver = _check_solver(self.solver, self.penalty, self.dual)\n  File \"C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\linear_model\\logistic.py\", line 446, in _check_solver\n    \"got %s penalty.\" % (solver, penalty))\nValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-3a0944c258bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgrid_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mparam_grid_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Training/Fitting Grid for Logistic Regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgrid_lr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mys_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_lr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./lr_model.sav'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dell\\AppData\\Roaming\\Python\\Python36\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty."
     ]
    }
   ],
   "source": [
    "param_grid_lr = {'penalty': ['l1','l2'], 'C': [0.001,0.01,0.1,1,10,100],'multi_class':['multinomial','auto']\n",
    "               ,'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag'],'n_jobs':[-1],'max_iter':[1000]}\n",
    "grid_lr = GridSearchCV(LogisticRegression() , param_grid_lr, cv = 2, n_jobs=-1, scoring='accuracy',verbose=1)\n",
    "# Training/Fitting Grid for Logistic Regression\n",
    "grid_lr.fit(Xs_train,ys_train)\n",
    "pickle.dump(grid_lr.best_estimator_, open('./lr_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-05T06:28:59.463431Z",
     "iopub.status.idle": "2022-02-05T06:28:59.463786Z",
     "shell.execute_reply": "2022-02-05T06:28:59.463608Z",
     "shell.execute_reply.started": "2022-02-05T06:28:59.463582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the best params which provide highest accuracy using different hyperparameter for Logistic regression model\n",
    "print(grid_lr.best_params_)\n",
    "print('LR accuracy on train data - ',grid_lr.score(Xs_train,ys_train))\n",
    "print('LR accuracy on test data - ',grid_lr.score(Xs_test,ys_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-05T06:28:59.465174Z",
     "iopub.status.idle": "2022-02-05T06:28:59.465462Z",
     "shell.execute_reply": "2022-02-05T06:28:59.465316Z",
     "shell.execute_reply.started": "2022-02-05T06:28:59.4653Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid_nb = {} # Gaussian NB does not have hyper parameters to tune.\n",
    "grid_nb = GridSearchCV(GaussianNB() , param_grid_nb, cv = 2, n_jobs=-1, scoring='accuracy',verbose=2)\n",
    "# Training/Fitting Grid for NB\n",
    "grid_nb.fit(Xs_train,ys_train)\n",
    "pickle.dump(grid_nb.best_estimator_, open('./nb_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-05T06:28:59.466135Z",
     "iopub.status.idle": "2022-02-05T06:28:59.466435Z",
     "shell.execute_reply": "2022-02-05T06:28:59.466281Z",
     "shell.execute_reply.started": "2022-02-05T06:28:59.466266Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the best params which provide highest accuracy using different hyperparameter for Logistic regression model\n",
    "print(grid_nb.best_params_)\n",
    "print('NB accuracy on train data - ',grid_nb.score(Xs_train,ys_train))\n",
    "print('NB accuracy on test data - ',grid_nb.score(Xs_test,ys_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-05T06:28:59.467923Z",
     "iopub.status.idle": "2022-02-05T06:28:59.468219Z",
     "shell.execute_reply": "2022-02-05T06:28:59.468074Z",
     "shell.execute_reply.started": "2022-02-05T06:28:59.468058Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid_knn = {'n_neighbors': [2,3,5],'algorithm': ['auto','brute'], 'n_jobs':[-1]}\n",
    "grid_knn = GridSearchCV(KNeighborsClassifier() , param_grid_knn, cv =2, n_jobs=-1, scoring='accuracy',verbose=2)\n",
    "# Training/Fitting Grid for KNN\n",
    "grid_knn.fit(Xs_train,ys_train)\n",
    "pickle.dump(grid_knn.best_estimator_, open('./knn_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-05T06:28:59.469487Z",
     "iopub.status.idle": "2022-02-05T06:28:59.46984Z",
     "shell.execute_reply": "2022-02-05T06:28:59.469658Z",
     "shell.execute_reply.started": "2022-02-05T06:28:59.469637Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the best params which provide highest accuracy using different hyperparameter for Logistic regression model\n",
    "print(grid_knn.best_params_)\n",
    "print('KNN accuracy on train data - ',grid_knn.score(Xs_train,ys_train))\n",
    "print('KNN accuracy on test data - ',grid_knn.score(Xs_test,ys_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-05T06:28:59.470653Z",
     "iopub.status.idle": "2022-02-05T06:28:59.470981Z",
     "shell.execute_reply": "2022-02-05T06:28:59.470837Z",
     "shell.execute_reply.started": "2022-02-05T06:28:59.47082Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid_dt = {'criterion': ['gini','entropy'],'max_depth': [3,5,7], 'max_features':['auto','log2']}\n",
    "grid_dt = GridSearchCV(DecisionTreeClassifier() , param_grid_dt, cv = 2, n_jobs=-1, scoring='accuracy',verbose=2)\n",
    "# Training/Fitting Grid for DT\n",
    "grid_dt.fit(Xs_train,ys_train)\n",
    "pickle.dump(grid_dt.best_estimator_, open('./dt_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-05T06:28:59.472001Z",
     "iopub.status.idle": "2022-02-05T06:28:59.47229Z",
     "shell.execute_reply": "2022-02-05T06:28:59.472149Z",
     "shell.execute_reply.started": "2022-02-05T06:28:59.472133Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finding the best params which provide highest accuracy using different hyperparameter for Logistic regression model\n",
    "print(grid_dt.best_params_)\n",
    "print('DT accuracy on train data - ',grid_dt.score(Xs_train,ys_train))\n",
    "print('DT accuracy on test data - ',grid_dt.score(Xs_test,ys_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tokenizer, open('./tokenizer.sav', 'wb'))\n",
    "pickle.dump(vectorizer, open('./vectorizer.sav', 'wb'))\n",
    "pickle.dump(smallEncoder, open('./smallEncoder.sav', 'wb'))\n",
    "pickle.dump(FullEncoder, open('./FullEncoder.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.models.load_model('./model-0.37.h5')\n",
    "model2 = pickle.load(open('./lr_model.sav', 'rb'))\n",
    "max_len = 200\n",
    "tokenizer = pickle.load(open('./tokenizer.sav', 'rb'))\n",
    "vectorizer = pickle.load(open('./vectorizer.sav', 'rb'))\n",
    "smallEncoder = pickle.load(open('./smallEncoder.sav', 'rb'))\n",
    "FullEncoder = pickle.load(open('./FullEncoder.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGroupAssignment(text):\n",
    "    text=dataCleaner(text)\n",
    "    if text.strip() == '' :\n",
    "        return 'GRP_0'\n",
    "    X1=pad_sequences(tokenizer.texts_to_sequences([text]), maxlen = max_len)\n",
    "    model1Pred=FullEncoder.inverse_transform(np.round(model1.predict(X1),0).astype(int))\n",
    "    \n",
    "    if model1Pred=='GRP_0':\n",
    "        return 'GRP_0'\n",
    "    else:\n",
    "        X2=vectorizer.transform([text])\n",
    "        X2=X2.toarray()\n",
    "        try:\n",
    "            model2Pred=smallEncoder.inverse_transform(model2.predict(X2))\n",
    "            model2Pred=model2Pred[0]\n",
    "        except:\n",
    "            model2Pred = 'GRP_0'\n",
    "        return model2Pred\n",
    "    \n",
    "    return 'GRP_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function getGroupAssignment is used to predict for new text.\n",
    "getGroupAssignment('when undocking pc , screen will not come back')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
